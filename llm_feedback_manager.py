#!/usr/bin/env python3
# llm_feedback_manager.py

import os
from gemini_test_rag import RAGSystem, create_rag_prompt, initialize_gemini

class LLMFeedbackManager:
    """
    LLM í”¼ë“œë°± ë§¤ë‹ˆì €: SPICE ë„·ë¦¬ìŠ¤íŠ¸ì™€ ì»´í¬ë„ŒíŠ¸ í•€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ë¶„ì„ ë° ëŒ€í™”í˜• ì±„íŒ…ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    def __init__(self, practice_circuit_topic: str = ""):
        """
        practice_circuit_topic: ì‹¤ìŠµ íšŒë¡œ ì£¼ì œ (ê¸°ë³¸ê°’ì€ ë¹ˆ ë¬¸ìì—´).
        """
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            self.rag_system = RAGSystem()
        except Exception as e:
            raise RuntimeError(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # Gemini ëª¨ë¸ ì´ˆê¸°í™”
        try:
            self.model, self.generation_config = initialize_gemini()
        except Exception as e:
            raise RuntimeError(f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        self.practice_circuit_topic = practice_circuit_topic
        self.first_turn = True

    def provide_initial_feedback(self, spice_file: str, component_pins, user_query: str) -> bool:
        """
        ì´ˆê¸° AI í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.
        - spice_file: SPICE ë„·ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        - component_pins: ì „ë‹¬ë°›ì€ ì»´í¬ë„ŒíŠ¸ í•€ ì •ë³´ (dict, list of tuples, list of dicts, or list of objects)
        - user_query: AIì—ê²Œ ë˜ì§ˆ ì²« ì§ˆë¬¸ í…ìŠ¤íŠ¸
        ë°˜í™˜ê°’: í”¼ë“œë°± ì œê³µ ì„±ê³µ ì—¬ë¶€
        """
        # SPICE íŒŒì¼ ì½ê¸°
        try:
            with open(spice_file, 'r', encoding='utf-8') as f:
                spice_text = f.read()
        except Exception as e:
            print(f"âŒ SPICE íŒŒì¼ '{spice_file}'ì„ ì½ëŠ” ë° ì‹¤íŒ¨: {e}")
            return False

        # component_pins í˜•ì‹ í™•ì¸ ë° ë³€í™˜
        items = []
        if isinstance(component_pins, dict):
            items = list(component_pins.items())
        elif isinstance(component_pins, list):
            for entry in component_pins:
                # íŠœí”Œ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœ with at least 2 elements
                if isinstance(entry, (tuple, list)) and len(entry) >= 2:
                    comp, pins = entry[0], entry[1]
                # dict í˜•íƒœ: 'component' ë˜ëŠ” 'class' í‚¤ ì‚¬ìš©
                elif isinstance(entry, dict) and 'pins' in entry:
                    if 'component' in entry:
                        comp = entry['component']
                    elif 'class' in entry:
                        comp = entry['class']
                    else:
                        print("âŒ component_pins ë¦¬ìŠ¤íŠ¸ dict í•­ëª©ì— 'component' ë˜ëŠ” 'class' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        return False
                    pins = entry['pins']
                # object í˜•íƒœ: ì†ì„± í™•ì¸
                elif hasattr(entry, 'component') and hasattr(entry, 'pins'):
                    comp, pins = entry.component, entry.pins
                else:
                    print(f"âŒ ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” entry í˜•ì‹: {entry!r} (type: {type(entry)})")
                    return False
                items.append((comp, pins))
        else:
            print("âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” component_pins í˜•ì‹ì…ë‹ˆë‹¤.")
            return False

        # component_pinsë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        pins_info = []
        for comp, pins in items:
            pins_info.append(f"{comp}: {pins}")
        pins_context = "\n".join(pins_info)

        # ë””ë²„ê¹… ì¶œë ¥: ë³€í™˜ëœ items
        print(f"ğŸ”§ component_pins ë³€í™˜ ê²°ê³¼: {items}")

        # ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        context = spice_text + "\n\n" + pins_context

        # RAG í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = create_rag_prompt(user_query, context, self.first_turn, self.practice_circuit_topic)
        self.first_turn = False

        # AI ì‘ë‹µ ìƒì„±
        try:
            response = self.model.generate_content(
                prompt,
                generation_config=self.generation_config
            )
            print(response.text)
            return True
        except Exception as e:
            print(f"âŒ AI í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
            return False

    def start_interactive_chat(self):
        """
        ì´ˆê¸° í”¼ë“œë°± ì´í›„ ì¶”ê°€ ëŒ€í™”ë¥¼ ìœ„í•œ ì¸í„°ë™í‹°ë¸Œ ì±„íŒ… ì„¸ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.
        """
        while True:
            user_input = input("\nğŸ’¬ ì§ˆë¬¸ ì…ë ¥ (ì¢…ë£Œ: 'exit'/'quit'): ").strip()
            if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ', 'q']:
                print("ğŸ‘ AI ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            if not user_input:
                print("âŒ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue

            # RAG ê²€ìƒ‰
            print("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...", end=" ")
            results = self.rag_system.search_similar_documents(user_input, top_k=3)
            print(f"({len(results)}ê°œ ë¬¸ì„œ ë°œê²¬)")

            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            context = self.rag_system.create_context(results)

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = create_rag_prompt(user_input, context, self.first_turn, self.practice_circuit_topic)
            self.first_turn = False

            # AI ì‘ë‹µ ìƒì„±
            print("ğŸ¤– AI: ", end="")
            try:
                response = self.model.generate_content(
                    prompt,
                    generation_config=self.generation_config
                )
                print(response.text)
            except Exception as e:
                print(f"âŒ ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
