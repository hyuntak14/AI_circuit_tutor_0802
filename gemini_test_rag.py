#!/usr/bin/env python3
# rag_gemini_chat.py

import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import numpy as np
import pandas as pd
import faiss
import google.generativeai as genai
from sentence_transformers import SentenceTransformer

class RAGSystem:
    def __init__(self, index_path="faiss_index.index", metadata_path="embedding_metadata.parquet"):
        """RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.index_path = index_path
        self.metadata_path = metadata_path
        self.index = None
        self.metadata = None
        self.embedding_model = None
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (FAISS ì¸ë±ìŠ¤ ìƒì„± ì‹œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•´ì•¼ í•¨)
        print("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        try:
            self.embedding_model = SentenceTransformer("intfloat/multilingual-e5-large-instruct")
            # GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸ (ì„ íƒ ì‚¬í•­)
            # import torch
            # if torch.cuda.is_available():
            #     print(f"âœ… SentenceTransformerê°€ GPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {torch.cuda.get_device_name(0)}")
            # else:
            #     print("âš ï¸ SentenceTransformerê°€ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            print("pip install sentence-transformers ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            raise

        # FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.load_database()
    
    def load_database(self):
        """FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            if os.path.exists(self.index_path):
                self.index = faiss.read_index(self.index_path)
                print(f"âœ… FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {self.index.ntotal}ê°œ ë²¡í„°")
            else:
                raise FileNotFoundError(f"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.index_path}")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            if os.path.exists(self.metadata_path):
                self.metadata = pd.read_parquet(self.metadata_path)
                print(f"âœ… ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.metadata)}ê°œ ë¬¸ì„œ")
            else:
                raise FileNotFoundError(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.metadata_path}")
            
            # ë°ì´í„° ì¼ê´€ì„± í™•ì¸
            if self.index.ntotal != len(self.metadata):
                print(f"âš ï¸ ê²½ê³ : ì¸ë±ìŠ¤ ë²¡í„° ìˆ˜({self.index.ntotal})ì™€ ë©”íƒ€ë°ì´í„° í–‰ ìˆ˜({len(self.metadata)})ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("FAISS ì¸ë±ìŠ¤ íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            raise
    
    def search_similar_documents(self, query, top_k=5):
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        try:
            # ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            # 1) GPU tensorë¡œ ì„ë² ë”© ìƒì„± (convert_to_tensor=True ì‹œ)
            query_embedding = self.embedding_model.encode(
                [query],
                convert_to_tensor=True,
                normalize_embeddings=True
            )
            # 2) CPUë¡œ ê°€ì ¸ì™€ì„œ numpy ë³€í™˜
            query_embedding = query_embedding.cpu().detach().numpy().astype('float32')
            
            # FAISS ê²€ìƒ‰
            distances, indices = self.index.search(query_embedding, top_k)
            
            # ê²°ê³¼ ì •ë¦¬
            results = []
            for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
                if idx < len(self.metadata):  # ìœ íš¨í•œ ì¸ë±ìŠ¤ì¸ì§€ í™•ì¸
                    doc_info = self.metadata.iloc[idx].to_dict()
                    results.append({
                        'rank': i + 1,
                        'similarity_score': float(1 / (1 + distance)),  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê°„ë‹¨í•œ ë°©ë²•)
                        'distance': float(distance),
                        'content': doc_info.get('chunk_text', ''),
                        'metadata': doc_info # ì›ë³¸ ë©”íƒ€ë°ì´í„° ì „ì²´ë¥¼ í¬í•¨
                    })
            
            return results
            
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def create_context(self, search_results, max_length=3000): # max_length ì•½ê°„ ì¦ê°€
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not search_results:
            return ""
        
        context_parts = []
        current_length = 0
        
        for result in search_results:
            content = result['content']
            
            # ê¸¸ì´ ì œí•œ í™•ì¸
            if current_length + len(content) > max_length:
                # ë‚¨ì€ ê³µê°„ë§Œí¼ë§Œ ì¶”ê°€
                remaining_space = max_length - current_length
                if remaining_space > 200:  # ìµœì†Œ 200ìëŠ” ìˆì–´ì•¼ ì˜ë¯¸ê°€ ìˆìŒ
                    content = content[:remaining_space] + "..." # ì˜ë¦° ë¶€ë¶„ì„ í‘œì‹œ
                    context_parts.append(f"[ë¬¸ì„œ {result['rank']}] {content}")
                break # ë” ì´ìƒ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
            
            context_parts.append(f"[ë¬¸ì„œ {result['rank']}] {content}")
            current_length += len(content)
        
        return "\n\n".join(context_parts)

def initialize_gemini():
    """Gemini APIë¥¼ ì´ˆê¸°í™”í•˜ê³  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤."""
    # ì¤‘ìš”: ì‹¤ì œ API í‚¤ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”.
    # ì•ˆì „ì„ ìœ„í•´ í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼ì—ì„œ ë¡œë“œí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    api_key = os.getenv("GOOGLE_API_KEY", "YOUR_GEMINI_API_KEY_HERE") # í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥

    if api_key == "YOUR_GEMINI_API_KEY_HERE" or not api_key:
        print("ê²½ê³ : GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì½”ë“œ ë‚´ í•˜ë“œì½”ë”©ëœ í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        print("ë˜ëŠ” 'export GOOGLE_API_KEY='your_api_key''ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        # ì•ˆì „ìƒì˜ ì´ìœ ë¡œ ì—¬ê¸°ì— ì§ì ‘ API í‚¤ë¥¼ ë„£ëŠ” ê²ƒì€ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì•„ë˜ ë¼ì¸ì˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤ì œ í‚¤ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
        api_key = "AIzaSyCxgQUQFLhTi-Y6nzRpdpgpgHO9xVJ-CAo" 
    
    genai.configure(api_key=api_key)

    generation_config = genai.GenerationConfig(
        temperature=0.4, # ì˜¨ë„ê°’ì„ ì¡°ê¸ˆ ë” ë‚®ì¶°ì„œ ì•ˆì •ì ì¸ ì‘ë‹µ ìœ ë„ (ê¸°ì¡´ 0.7ì—ì„œ ë³€ê²½)
        max_output_tokens=1500 # ì¶œë ¥ í† í° ìˆ˜ ì¦ê°€ (í•„ìš”ì‹œ ì¡°ì ˆ)
    )

    model_names = [
        "models/gemini-2.5-flash", # ë” ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ flash ëª¨ë¸ ìš°ì„  ê³ ë ¤
        "models/gemini-2.5-pro",   # ë” ê°•ë ¥í•œ ì„±ëŠ¥ì„ ìœ„í•´ pro ëª¨ë¸ ê³ ë ¤
    ]

    for model_name in model_names:
        try:
            print(f"ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘: {model_name}")
            model = genai.GenerativeModel(model_name)
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜¸ì¶œ
            test_response = model.generate_content(
                "ì•ˆë…•í•˜ì„¸ìš”! ë‹¹ì‹ ì€ ëˆ„êµ¬ì¸ê°€ìš”? ê°„ë‹¨íˆ ë‹µí•´ì£¼ì„¸ìš”.",
                generation_config=generation_config
            )
            if test_response.text:
                print(f"âœ… {model_name} ì‚¬ìš© ê°€ëŠ¥!")
                return model, generation_config
            else:
                print(f"âŒ {model_name} ì‘ë‹µ ì—†ìŒ (text í•„í„°ë§ë¨).")
        except Exception as e:
            print(f"âŒ {model_name} ì‚¬ìš© ë¶ˆê°€: {e}")
            continue
    
    raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

def create_rag_prompt(user_query, context, is_first_turn, practice_circuit_topic=""):
    """
    RAGìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    Args:
        user_query (str): ì‚¬ìš©ìì˜ í˜„ì¬ ì§ˆë¬¸.
        context (str): ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©.
        is_first_turn (bool): í˜„ì¬ í„´ì´ ì²« ë²ˆì§¸ í„´ì¸ì§€ ì—¬ë¶€.
        practice_circuit_topic (str): ì‹¤ìŠµ íšŒë¡œì˜ ì£¼ì œ (ì²« í„´ì—ë§Œ í•´ë‹¹).
    """
    if is_first_turn:
        # ì²« ë²ˆì§¸ í„´: ë„·ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ë° ì‹¤ìŠµ ì£¼ì œ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸ì— ì§‘ì¤‘
        if context.strip():
            prompt = f"""ë‹¹ì‹ ì€ ì „ì íšŒë¡œ ì„¤ê³„ ë° ë¶„ì„ì„ ë•ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•œ ë„·ë¦¬ìŠ¤íŠ¸ì™€ ì‹¤ìŠµ ë³´ê³ ì„œ ê´€ë ¨ ì°¸ê³  ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
íŠ¹íˆ, ì£¼ì–´ì§„ ë„·ë¦¬ìŠ¤íŠ¸ì— ì ì¬ì ì¸ ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ì‹¤ìŠµ ì£¼ì œì¸ '{practice_circuit_topic}' íšŒë¡œì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ë©´ë°€íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.
**ë¶„ì„ ê²°ê³¼ ì˜¤ë¥˜ë‚˜ ë¶ˆì¼ì¹˜(ì°¨ì´ì )ê°€ ë°œê²¬ë˜ë©´, ë‹¤ìŒ í˜•ì‹ì— ë”°ë¼ êµ¬ì²´ì ì´ê³  ê¸°ìˆ ì ì¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ëª…í•´ì£¼ì„¸ìš”.**
ë‹µë³€ì€ í•­ìƒ ê°ê´€ì ì´ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ë©°, ì–´ë–¤ ì¢…ë¥˜ì˜ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì€ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

--- ì°¸ê³  ìë£Œ (ë„·ë¦¬ìŠ¤íŠ¸ ë° ê´€ë ¨ íšŒë¡œ ì •ë³´) ---
{context}

--- ì‚¬ìš©ìì˜ ì§ˆë¬¸ ---
{user_query}

--- ë‹µë³€ í˜•ì‹ (ì²« ë²ˆì§¸ ë‹µë³€) ---
1.  **ê°œìš”:** ë„·ë¦¬ìŠ¤íŠ¸ ë¶„ì„ ë° ì‹¤ìŠµ íšŒë¡œ ì¼ì¹˜ ì—¬ë¶€ì— ëŒ€í•œ í•µì‹¬ ìš”ì•½. (ì˜ˆ: "ë„·ë¦¬ìŠ¤íŠ¸ëŠ” ì •ìƒì ì´ë©° ì‹¤ìŠµ íšŒë¡œì™€ ì¼ì¹˜í•©ë‹ˆë‹¤." ë˜ëŠ” "ë„·ë¦¬ìŠ¤íŠ¸ì— ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìœ¼ë©° ì‹¤ìŠµ íšŒë¡œì™€ ì¼ë¶€ ë‹¤ë¦…ë‹ˆë‹¤.")
2.  **ë¶„ì„ ê²°ê³¼:**
    * **ë„·ë¦¬ìŠ¤íŠ¸ ì˜¤ë¥˜ ì—¬ë¶€:** ë„·ë¦¬ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ êµ¬ì²´ì ì¸ ë¬¸ë²•ì /ë…¼ë¦¬ì  ì˜¤ë¥˜ (ì˜ˆ: "Component Xì˜ ì—°ê²°ì´ ì˜ëª»ë¨", "Net Yì˜ ì •ì˜ ëˆ„ë½" ë“±). ì˜¤ë¥˜ê°€ ì—†ë‹¤ë©´ "ë„·ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì˜¤ë¥˜ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."ë¡œ ê¸°ì¬.
    * **ì‹¤ìŠµ íšŒë¡œ ì¼ì¹˜ ì—¬ë¶€:** '{practice_circuit_topic}' íšŒë¡œì˜ ì˜ˆìƒë˜ëŠ” êµ¬ì¡°/íŠ¹ì„±ê³¼ ë¹„êµí•˜ì—¬, ë„·ë¦¬ìŠ¤íŠ¸ê°€ ì–´ë–¤ ë¶€ë¶„ì´ ì¼ì¹˜í•˜ê³  ì–´ë–¤ ë¶€ë¶„ì´ ë‹¤ë¥¸ì§€ ëª…í™•í•˜ê²Œ ì„¤ëª…. (ì˜ˆ: "ì €í•­ R1ì˜ ê°’ì´ ì‹¤ìŠµ ê°€ì´ë“œì™€ ë‹¤ë¦…ë‹ˆë‹¤.", "Op-Ampì˜ í”¼ë“œë°± ë£¨í”„ êµ¬ì„±ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤." ë“±). ì™„ì „íˆ ì¼ì¹˜í•œë‹¤ë©´ "ë„·ë¦¬ìŠ¤íŠ¸ëŠ” ì‹¤ìŠµ ì£¼ì œì¸ '{practice_circuit_topic}' íšŒë¡œì™€ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤."ë¡œ ê¸°ì¬.
3.  **ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:** ì‚¬ìš©ìê°€ ë„·ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, íšŒë¡œë¥¼ ê°œì„ í•˜ê±°ë‚˜, ì¶”ê°€ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ ë„ì›€ì´ ë  ë§Œí•œ êµ¬ì²´ì ì¸ ì¡°ì¹˜ ë˜ëŠ” ê¶Œì¥ ì‚¬í•­.

--- ë‹µë³€ ---
"""
        else:
            prompt = f"""ë‹¹ì‹ ì€ ì „ì íšŒë¡œ ì„¤ê³„ ë° ë¶„ì„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìë‹˜, í˜„ì¬ ë„·ë¦¬ìŠ¤íŠ¸ ì •ë³´ê°€ ì¶©ë¶„íˆ ì œê³µë˜ì§€ ì•Šì•„ ìš”ì²­í•˜ì‹  ë¶„ì„ì„ ì§„í–‰í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

--- ì‚¬ìš©ìì˜ ì§ˆë¬¸ ---
{user_query}

--- ë‹µë³€ ---
ë„·ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ê´€ë ¨ ì‹¤ìŠµ ìë£Œê°€ ë¶€ì¡±í•˜ì—¬ ìš”ì²­í•˜ì‹  ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„·ë¦¬ìŠ¤íŠ¸ ë‚´ìš©ì„ ì œê³µí•´ì£¼ì‹œê±°ë‚˜, ì–´ë–¤ ì¢…ë¥˜ì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ê³  ì‹¶ìœ¼ì‹ ì§€ ë” ìì„¸íˆ ì•Œë ¤ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ë‹µë³€ì€ í•­ìƒ ê°ê´€ì ì´ê³  ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ë©°, ì–´ë–¤ ì¢…ë¥˜ì˜ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì€ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
"""
    else:
        # ì´í›„ í„´: ì¼ë°˜ì ì¸ Q&A (RAG í™œìš©)
        if context.strip():
            prompt = f"""ë‹¹ì‹ ì€ ì „ì íšŒë¡œ ì„¤ê³„ ë° ë¶„ì„ì„ ë•ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì œê³µëœ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
**ë‹µë³€ì€ í•­ìƒ ê¸°ìˆ ì ì´ê³  ê°ê´€ì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ë©°, ì–´ë–¤ ì¢…ë¥˜ì˜ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
ë§Œì•½ ì°¸ê³  ë¬¸ì„œì— ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ì •ë³´ê°€ ì—†ë‹¤ë©´, ì¼ë°˜ì ì¸ ì „ì íšŒë¡œ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë‹µë³€ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.

--- ì°¸ê³  ë¬¸ì„œ ---
{context}

--- ì‚¬ìš©ìì˜ ì§ˆë¬¸ ---
{user_query}

--- ë‹µë³€ í˜•ì‹ (ì´í›„ ë‹µë³€) ---
* **ìš”ì•½:** ì§ˆë¬¸ì— ëŒ€í•œ í•µì‹¬ ë‚´ìš©ì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•©ë‹ˆë‹¤.
* **ìƒì„¸ ì„¤ëª…:** ì§ˆë¬¸ì— ëŒ€í•œ ìì„¸í•˜ê³  í¬ê´„ì ì¸ ì„¤ëª…ì…ë‹ˆë‹¤. í•„ìš”ì‹œ ì˜ˆì‹œë‚˜ ê´€ë ¨ ê°œë…ì„ í¬í•¨í•©ë‹ˆë‹¤.
* **ê²°ë¡  ë° ì¶”ê°€ ì •ë³´:** ë‹µë³€ì˜ ë§ˆë¬´ë¦¬ ë˜ëŠ” ì¶”ê°€ì ìœ¼ë¡œ ë„ì›€ì´ ë  ë§Œí•œ ê´€ë ¨ ì •ë³´ë‚˜ ì œì•ˆì…ë‹ˆë‹¤.

--- ë‹µë³€ ---
"""
        else:
            prompt = f"""ë‹¹ì‹ ì€ ì „ì íšŒë¡œ ì„¤ê³„ ë° ë¶„ì„ì„ ë•ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì°¸ê³  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì „ì íšŒë¡œ ì§€ì‹ì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ê² ìŠµë‹ˆë‹¤.
**ë‹µë³€ì€ í•­ìƒ ê¸°ìˆ ì ì´ê³  ê°ê´€ì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ë©°, ì–´ë–¤ ì¢…ë¥˜ì˜ ìœ í•´í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ ë‚´ìš©ì„ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**

--- ì‚¬ìš©ìì˜ ì§ˆë¬¸ ---
{user_query}

--- ë‹µë³€ ---
"""

    return prompt

def chat_with_rag():
    """RAG ì‹œìŠ¤í…œê³¼ Geminië¥¼ ê²°í•©í•œ ì±„íŒ… í•¨ìˆ˜ (ì²« ì‘ë‹µ/ì´í›„ ì‘ë‹µ í˜•ì‹ ë¶„ê¸° í¬í•¨)"""
    # 1) RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    try:
        rag_system = RAGSystem()
    except Exception as e:
        print(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤: {e}")
        return

    # 2) Gemini ëª¨ë¸ ì´ˆê¸°í™”
    print("Gemini ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    try:
        model, generation_config = initialize_gemini()
    except Exception as e:
        print(f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤: {e}")
        return
    
    # === ì‚¬ìš©ì ì •ì˜ ì„¤ì • ===
    # ì‹¤ìŠµ íšŒë¡œì˜ ì£¼ì œë¥¼ ì—¬ê¸°ì— ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤.
    # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì´ ê°’ì„ ë™ì ìœ¼ë¡œ ì…ë ¥ë°›ê±°ë‚˜ ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œ ê°€ì ¸ì™€ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    practice_circuit_topic = "Op-Amp Inverting Amplifier (ë°˜ì „ ì¦í­ê¸°)" 
    # ======================

    first_turn = True
    
    print("\n" + "="*60)
    print("ğŸ¤– RAG + Gemini ì±„íŒ… ì‹œì‘! (ì¢…ë£Œ: quit/exit/ì¢…ë£Œ)")
    print("============================================================")
    print(f"ğŸ’¡ í˜„ì¬ ì‹¤ìŠµ ì£¼ì œ: {practice_circuit_topic}")
    print("============================================================")
    
    while True:
        user_input = input("\në‹¹ì‹ : ").strip()
        if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("ğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        if not user_input:
            print("âŒ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        # 3) ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        print("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...", end=" ", flush=True)
        search_results = rag_system.search_similar_documents(user_input, top_k=3)
        print(f"({len(search_results)}ê°œ ë¬¸ì„œ ë°œê²¬)")
        
        # 4) ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = rag_system.create_context(search_results)
        
        # 5) RAG í”„ë¡¬í”„íŠ¸ ìƒì„± (modified call)
        rag_prompt = create_rag_prompt(user_input, context, first_turn, practice_circuit_topic)

        # ì²« í„´ ì´í›„ì—ëŠ” first_turnì„ Falseë¡œ ì„¤ì •
        if first_turn:
            first_turn = False

        
        # 6) Geminië¡œ ë‹µë³€ ìƒì„±
        print("ğŸ¤– Gemini: ", end="", flush=True)
        try:
            response = model.generate_content(
                rag_prompt,
                generation_config=generation_config
            )
            print(response.text)
        except genai.types.BlockedPromptException as e:
            # BlockedPromptExceptionì€ ì•ˆì „ í•„í„°ì— ì˜í•œ ì°¨ë‹¨ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            print(f"âŒ ìƒì„± ì˜¤ë¥˜: í”„ë¡¬í”„íŠ¸ê°€ ì•ˆì „ ì •ì±…ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. (finish_reason: {e.response.prompt_feedback.block_reason})")
            print("ì´ì „ ì§ˆë¬¸, ê²€ìƒ‰ëœ ë¬¸ì„œ(ì»¨í…ìŠ¤íŠ¸), ë˜ëŠ” í˜„ì¬ ì§ˆë¬¸ì— ë¶€ì ì ˆí•˜ê±°ë‚˜ ìœ í•´í•˜ë‹¤ê³  íŒë‹¨ë  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            print(f"ìì„¸í•œ ì‘ë‹µ: {e.response}") # ë” ìì„¸í•œ ì •ë³´ ì¶œë ¥
        except Exception as e:
            print(f"âŒ ìƒì„± ì˜¤ë¥˜: {e}")
            # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ (e.g., ë„¤íŠ¸ì›Œí¬, API í‚¤ ë¬¸ì œ ë“±)
            if "finish_reason" in str(e) and "2" in str(e):
                print("ì´ëŠ” ì£¼ë¡œ ì•ˆì „ í•„í„°(Safety Filter)ì— ì˜í•´ ì‘ë‹µì´ ì°¨ë‹¨ë  ë•Œ ë°œìƒí•©ë‹ˆë‹¤.")
                print("í”„ë¡¬í”„íŠ¸ì— í¬í•¨ëœ ë‚´ìš©(ì§ˆë¬¸, ì»¨í…ìŠ¤íŠ¸)ì— ë¬¸ì œê°€ ì—†ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸í•´ë³´ì„¸ìš”.")
            print(f"ë°œìƒí•œ ì˜¤ë¥˜ ìœ í˜•: {type(e)}")

        # 7) ì°¸ê³  ë¬¸ì„œ ì •ë³´ í‘œì‹œ (ì˜µì…˜)
        if search_results:
            print(f"\nğŸ“š ì°¸ê³  ë¬¸ì„œ: {len(search_results)}ê°œ (ìµœê³  ìœ ì‚¬ë„ {search_results[0]['similarity_score']:.3f})")
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì°¸ê³  ë¬¸ì„œì˜ contentë„ ì¶œë ¥í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # for res in search_results:
            #     print(f"  - Rank {res['rank']} (Score: {res['similarity_score']:.2f}): {res['content'][:100]}...")

def main():
    # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    required_packages = ['faiss-cpu', 'sentence-transformers', 'pandas', 'numpy', 'google-generativeai']
    missing_packages = []
    
    try:
        import faiss
        import sentence_transformers
        import pandas
        import numpy
        import google.generativeai
    except ImportError as e:
        missing_module = str(e).split("'")[1]
        if missing_module == 'faiss':
            missing_packages.append('faiss-cpu')
        elif missing_module == 'google': # google.generativeai
            missing_packages.append('google-generativeai')
        else:
            missing_packages.append(missing_module)
    
    if missing_packages:
        print("âŒ ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
        for pkg in missing_packages:
            print(f"   pip install {pkg}")
        return
    
    chat_with_rag()

if __name__ == "__main__":
    main()