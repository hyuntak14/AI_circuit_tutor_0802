import os
import streamlit as st
import cv2
import numpy as np
from PIL import Image
from streamlit_drawable_canvas import st_canvas
from detector.fasterrcnn_detector import FasterRCNNDetector

# ì ˆëŒ€ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "model", "fasterrcnn.pt")

# ìº”ë²„ìŠ¤ ìµœëŒ€ í¬ê¸°
MAX_DISPLAY_WIDTH = 800
MAX_DISPLAY_HEIGHT = 600

def main():
    st.title("ğŸ“¸ Breadboard to Schematic")

    uploaded = st.file_uploader("Upload breadboard image", type=["jpg","png","jpeg"])
    if not uploaded:
        st.info("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        return

    # ì›ë³¸ ë¡œë“œ
    data = np.frombuffer(uploaded.read(), np.uint8)
    img = cv2.imdecode(data, cv2.IMREAD_COLOR)
    h, w = img.shape[:2]

    # ì¶•ì†Œëœ ë””ìŠ¤í”Œë ˆì´ìš© í¬ê¸° ê³„ì‚°
    scale = min(MAX_DISPLAY_WIDTH / w, MAX_DISPLAY_HEIGHT / h, 1.0)
    disp_w, disp_h = int(w * scale), int(h * scale)
    disp_img = cv2.resize(img, (disp_w, disp_h))

    st.subheader("1. Original Image (for corner adjust)")
    st.image(cv2.cvtColor(disp_img, cv2.COLOR_BGR2RGB), use_container_width=False)

    # Faster R-CNNìœ¼ë¡œ breadboard bbox ê²€ì¶œ
    detector = FasterRCNNDetector(model_path=MODEL_PATH)
    dets = detector.detect(img)
    bb = next((box for cls,_,box in dets if cls.lower()=="breadboard"), None)
    if bb is None:
        st.error("ë¹µíŒì„ ê²€ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    x1,y1,x2,y2 = bb

    # ì›ë³¸ ì¢Œí‘œ ê¸°ì¤€ 4ê°œ ê¼­ì§“ì 
    default_pts = [
        (x1, y1),
        (x2, y1),
        (x2, y2),
        (x1, y2),
    ]
    # ë””ìŠ¤í”Œë ˆì´ìš© ìŠ¤ì¼€ì¼ë§
    scaled_pts = [(int(x*scale), int(y*scale)) for x,y in default_pts]

    # â€œí•¸ë“¤â€ í¬ê¸°
    # â€œí•¸ë“¤â€ í¬ê¸°
    HANDLE_SIZE = 16

    # initial_drawing: 4ê°œì˜ ì‘ì€ ì‚¬ê°í˜•(handle) ê°ì²´ë§Œ ìƒì„±
    handles = []
    for (cx, cy) in scaled_pts:
        handles.append({
            "type": "rect",
            "left": cx - HANDLE_SIZE//2,
            "top": cy - HANDLE_SIZE//2,
            "width": HANDLE_SIZE,
            "height": HANDLE_SIZE,
            "stroke": "red",                # â† strokeColor ëŒ€ì‹  stroke
            "strokeWidth": 2,
            "fill": "rgba(255,0,0,0.3)",    # â† fillColor ëŒ€ì‹  fill
            "cornerColor": "red",
            "cornerSize": 6,
            "transparentCorners": False,
        })

    st.subheader("2. Adjust 4 Corner Handles")
    st.write("íŒŒë€ ë„¤ëª¨ë¥¼ ë“œë˜ê·¸í•˜ì—¬ ê° ê¼­ì§“ì ì„ ë§ì¶°ì£¼ì„¸ìš”.")

    canvas_res = st_canvas(
        background_image=Image.fromarray(cv2.cvtColor(disp_img, cv2.COLOR_BGR2RGB)),
        width=disp_w, height=disp_h,
        drawing_mode="transform",    # ê¸°ì¡´ ê°ì²´(ì‚¬ê°í˜•)ë§Œ ì›€ì§ì¼ ìˆ˜ ìˆìŒ
        initial_drawing={"objects": handles},
        key="corner_adjust"
    )

    # ì´ë™ëœ handleë“¤ì˜ ì¤‘ì‹¬ì„ ì›ë³¸ ì¢Œí‘œë¡œ ë³µì›
    if canvas_res.json_data and canvas_res.json_data.get("objects"):
        src = []
        for obj in canvas_res.json_data["objects"]:
            left = obj["left"]
            top  = obj["top"]
            w_obj = obj["width"]
            h_obj = obj["height"]
            # ì‚¬ê°í˜• ì¤‘ì•™ì´ ì‹¤ì œ ê¼­ì§“ì 
            cx_disp = left + w_obj/2
            cy_disp = top  + h_obj/2
            # ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ì—­ë³€í™˜
            src.append([cx_disp/scale, cy_disp/scale])
        src = np.float32(src)
    else:
        # ì¡°ì • ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ê·¸ëŒ€ë¡œ
        src = np.float32(default_pts)

    # Perspective Warp
    dst = np.float32([[0,0], [w,0], [w,h], [0,h]])
    M = cv2.getPerspectiveTransform(src, dst)
    warped = cv2.warpPerspective(img, M, (w, h))
    warped_raw = warped.copy()
    st.subheader("3. Transformed Image")
    st.image(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB), use_container_width=True)


    
    # 4) Component Detection & Manual Edit
    st.subheader("4. Component Detection & Manual Edit")

    # â¤ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ & ìƒ‰ìƒ ë§µ
    CLASS_LIST    = ['Resistor','LED','Diode','IC','Line_area','Capacitor']
    CLASS_OPTIONS = ['Unassigned'] + CLASS_LIST
    COLOR_MAP = {
        'Resistor':  '#e63946',
        'LED':       '#f4a261',
        'Diode':     '#457b9d',
        'IC':        '#9d4edd',
        'Line_area': '#2a9d8f',
        'Capacitor': '#6c757d'
    }
    DEFAULT_COLOR = '#6c757d'

    # â¤ ëª¨ë“œ ì„ íƒ
    mode = st.radio("ğŸ› ï¸ Mode", ["Adjust","Add New"], horizontal=True)
    drawing_mode = "transform" if mode=="Adjust" else "rect"
    st.write(f"í˜„ì¬ ëª¨ë“œ: **{mode}**")

    # â¤ ë””ìŠ¤í”Œë ˆì´ìš© warped ì´ë¯¸ì§€
    disp_warp = cv2.resize(warped, (disp_w, disp_h))
    disp_rgb  = cv2.cvtColor(disp_warp, cv2.COLOR_BGR2RGB)

    # â¤ ìµœì´ˆ ê²€ì¶œëœ ì»´í¬ë„ŒíŠ¸
    detector = FasterRCNNDetector(model_path=MODEL_PATH)
    raw = detector.detect(warped)
    comps = [{'class':c,'bbox':b} for c,_,b in raw if c.lower()!='breadboard']

    # â¤ initial drawing ìƒì„±
    handles = []
    for comp in comps:
        cls = comp['class']
        col = COLOR_MAP.get(cls, DEFAULT_COLOR)
        x1,y1,x2,y2 = comp['bbox']
        handles.append({
            "type": "rect",
            "left":   x1*scale,
            "top":    y1*scale,
            "width":  (x2-x1)*scale,
            "height": (y2-y1)*scale,
            "stroke": col,
            "strokeWidth": 2,
            "fill":   f"{col}33",
            "cornerColor": col,
            "cornerSize": 6,
            "transparentCorners": False,
        })

    # â¤ ìº”ë²„ìŠ¤ ì˜µì…˜ êµ¬ì„±
    canvas_args = dict(
        background_image=Image.fromarray(disp_rgb),
        width=disp_w, height=disp_h,
        drawing_mode=drawing_mode,
        initial_drawing={"objects": handles},
        key="comp_edit"
    )
    if mode=="Add New":
        # ìƒˆë¡œ ê·¸ë¦¬ëŠ” ë°•ìŠ¤ì˜ ê¸°ë³¸ ìŠ¤íƒ€ì¼
        canvas_args.update({
            "stroke_width": 2,
            "stroke_color": DEFAULT_COLOR,
            "fill_color":   "rgba(0,0,0,0)"
        })

    canvas_comp = st_canvas(**canvas_args)

    # â¤ updated ë¦¬ìŠ¤íŠ¸ ìƒì„±
    updated = []
    if canvas_comp.json_data and canvas_comp.json_data.get("objects"):
        for idx, obj in enumerate(canvas_comp.json_data["objects"]):
            left, top = obj["left"]/scale, obj["top"]/scale
            w_box, h_box = obj["width"]/scale, obj["height"]/scale
            x1n, y1n = int(left),       int(top)
            x2n, y2n = int(left+w_box), int(top+h_box)
            # ê¸°ì¡´ ì¸ì‹ ê°ì²´ë©´ ì›ë˜ í´ë˜ìŠ¤, ì•„ë‹ˆë©´ None
            orig_cls = comps[idx]['class'] if idx < len(comps) else None
            updated.append({'bbox': (x1n,y1n,x2n,y2n), 'class': orig_cls})
    else:
        updated = [{'bbox':c['bbox'], 'class':c['class']} for c in comps]

    # â¤ ì‚­ì œ/í´ë˜ìŠ¤ ë³€ê²½ UI
    st.subheader("5. Review & Edit Components")
    final_comps = []
    cols = st.columns([1,3,3])
    for i, comp in enumerate(updated):
        do_del = cols[0].checkbox("Delete", key=f"del_{i}")
        cls_sel = cols[1].selectbox(
            "Class",
            CLASS_OPTIONS,
            index=CLASS_OPTIONS.index(comp['class']) if comp['class'] in CLASS_OPTIONS else 0,
            key=f"class_{i}"
        )
        coords = f"{comp['bbox'][0]}, {comp['bbox'][1]} - {comp['bbox'][2]}, {comp['bbox'][3]}"
        cols[2].write(coords)
        if not do_del:
            final_comps.append({
                'bbox': comp['bbox'],
                'class': cls_sel if cls_sel!='Unassigned' else None
            })

    # â¤ ìµœì¢… ë°•ìŠ¤ ì‹œê°í™”
    viz = disp_warp.copy()
    for comp in final_comps:
        x1,y1,x2,y2 = [int(c*scale) for c in comp['bbox']]
        col = COLOR_MAP.get(comp['class'], DEFAULT_COLOR)
        bgr = tuple(int(col.lstrip('#')[i:i+2], 16) for i in (4,2,0))
        cv2.rectangle(viz, (x1,y1), (x2,y2), bgr, 2)
    st.image(cv2.cvtColor(viz, cv2.COLOR_BGR2RGB), caption="Final Boxes", use_container_width=False)

    # â†’ final_compsë¥¼ ë‹¤ìŒ ë‹¨ê³„ì— ë„˜ê²¨ì£¼ì„¸ìš”.

        # 3) Perspective Warp ê¹Œì§€ ëë‚œ ë’¤ ë°”ë¡œ ì¶”ê°€
        # --- after `warped_raw = warped.copy()` ---

    st.subheader("4. Template Holes Adjustment & Fallback")

    from detector.hole_detector import HoleDetector
    hd = HoleDetector(
        template_csv_path=os.path.join(BASE_DIR, "detector", "template_holes_complete.csv"),
        template_image_path=os.path.join(BASE_DIR, "detector", "breadboard18.jpg"),
        max_nn_dist=20.0
    )

    # (1) load raw template pts
    tpl_raw = np.loadtxt(hd.template_csv_path, delimiter=',')  # shape (N,2)

    # (2) scale template â†’ warped_raw coords
    tpl_img = cv2.imread(hd.template_image_path)
    th, tw = tpl_img.shape[:2]
    H, W = warped_raw.shape[:2]
    scale_model_x, scale_model_y = W/tw, H/th
    tpl_scaled = [(x*scale_model_x, y*scale_model_y) for x,y in tpl_raw]

    # (3) display scaling: warped_raw â†’ disp_warp
    #    ì´ë¯¸ disp_warp = resize(warped_raw, (disp_w, disp_h)) ë¡œ ë§Œë“¤ì–´ ë‘ì…¨ìŠµë‹ˆë‹¤.
    disp_tpl = [(x*scale, y*scale) for x,y in tpl_scaled]

    # (4) build handles for tpl_scaled
    HANDLE = 8
    tpl_handles = []
    for cx, cy in disp_tpl:
        tpl_handles.append({
            "type": "rect",
            "left": cx - HANDLE/2,
            "top":  cy - HANDLE/2,
            "width":  HANDLE,
            "height": HANDLE,
            "stroke": "#ffba08",
            "strokeWidth": 2,
            "fill":   "rgba(255,186,8,0.3)",
            "cornerColor": "#ffba08",
            "cornerSize": 6,
            "transparentCorners": False,
        })

    st.write("í…œí”Œë¦¿ ê¸°ë°˜ êµ¬ë© í¬ì¸íŠ¸ë¥¼ ì§ì ‘ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    canvas_tpl = st_canvas(
        background_image=Image.fromarray(disp_rgb),
        width=disp_w, height=disp_h,
        drawing_mode="transform",
        initial_drawing={"objects": tpl_handles},
        key="tpl_adjust"
    )

    # (5) recover user-adjusted template pts â†’ warp coords
    if canvas_tpl.json_data and canvas_tpl.json_data.get("objects"):
        user_tpl = []
        for obj in canvas_tpl.json_data["objects"]:
            cx = obj["left"] + obj["width"]/2
            cy = obj["top"]  + obj["height"]/2
            user_tpl.append( (cx/scale, cy/scale) )
    else:
        user_tpl = tpl_scaled  # no adjustment

    # --- now do hole detection with fallback ---

    st.subheader("5. Hole Detection & Net Clustering")

    # try main.py ë°©ì‹
    try:
        holes = hd.detect_holes(warped_raw)
        st.success(f"âœ… detect_holes succeeded: {len(holes)} points")
    except ValueError as e:
        st.warning(f"detect_holes failed ({e})\nâ†’ í…œí”Œë¦¿ í¬ì¸íŠ¸ ì‚¬ìš©({len(user_tpl)}ê°œ)")
        holes = user_tpl

    # cluster nets
    try:
        nets, row_nets = hd.get_board_nets(holes, base_img=warped_raw, show=False)
        st.success(f"âœ… Nets: {len(nets)} clusters")
    except ValueError as e:
        st.warning(f"Net clustering failed ({e}) â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸")
        nets, row_nets = [], []

    # visualize hole clusters
    vis = warped_raw.copy()
    rng = np.random.default_rng(0)
    for _, clusters in row_nets:
        for entry in clusters:
            col = tuple(int(c) for c in rng.integers(0,256,3))
            for x,y in entry['pts']:
                cv2.circle(vis, (int(x),int(y)), 3, col, -1)
    st.image(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB),
             caption="Hole Clusters", use_container_width=True)

    # prepare holeâ†’net map
    hole_to_net = {
        (int(round(x)), int(round(y))): entry['net_id']
        for _, clusters in row_nets
        for entry in clusters
        for x,y in entry['pts']
    }


if __name__ == "__main__":
    main()
